{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1McUnVJte9bRnrwSEo8cDUGnSPq8UiFnd",
      "authorship_tag": "ABX9TyM8yDK7zHzNLMwWLIMBvpcW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ethansong206/Climate-Plus-Project/blob/main/DataCleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "e6u2wlQbblpm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import re\n",
        "import seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load csv and clean locations + dates\n",
        "DiningDataFull = pd.read_csv('/content/drive/MyDrive/Data+/Climate+ Data 2019 thru 2023.csv',\n",
        "                             dtype = {'Priority 1': str, 'Priority 2': str,\n",
        "                                      'Priority 3': str})\n",
        "#print(DiningDataFull['Unit Name'].value_counts()) # Show how many entries there are of each location\n",
        "\n",
        "#below code to make 'Unit Name' column easier to handle\n",
        "#can add more lines given more locations\n",
        "def location_rename(location):\n",
        "    if(\"Marketplace\" in location): #Combine data for Marketplace Kitchen and Marketplace Special Event\n",
        "        return \"Marketplace\"\n",
        "    if(\"Marine Lab\" in location):\n",
        "        return \"DuML\"\n",
        "    if(\"Trinity\" in location):\n",
        "        return \"Trinity\"\n",
        "    if(\"Freeman\" in location):\n",
        "        return \"Freeman\"\n",
        "    return None\n",
        "\n",
        "DiningDataFull['Unit Name'] = DiningDataFull.apply(lambda d: location_rename(d['Unit Name']), axis = 1)\n",
        "\n",
        "DiningDataFull['Purchase Date'] = DiningDataFull.apply(lambda d: datetime.strptime(d['Purchase Date'], '%m/%d/%Y').date(), axis = 1)\n",
        "\n",
        "print(\"Rows in DiningDataFull: \", DiningDataFull.shape[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6FApqgppspd",
        "outputId": "3a000b21-2b6e-4342-9bad-14bc3ab80a91",
        "cellView": "form"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows in DiningDataFull:  90534\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Extract the unit names for each item into a new column called `Unit`, then rename each unit into a more simple label (i.e. LB CS to LB). Convert cans and bottle cases into the equivalent value in OZ.\n",
        "\n",
        "Extract the simplified item name from `Vendor Item Description` into a new column called `Item Name`.\n",
        "\n",
        "---\n",
        "Note on Exclusion: Some units are left out in this first calculation of emissions as they are either not directly food (i.e. gloves) or are too difficult to go through individually and find a measurement that is not ambiguous. The total number of entries left out is 12171. **The number of non-food items in this amount can be calculated later.**\n",
        "\n",
        "---\n",
        "Note on Conversions: The column `Vendor Item Purchase Unit` is in the format x/y n which should be read as x bags of y units of n food.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "y6s4AxAUOoKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Extract and clean units and item names\n",
        "#this code extracts just the unit information\n",
        "DiningDataFull['Unit'] = DiningDataFull['Vendor Item Purchase Unit'].str.extract(r\" ?([A-Za-zÀ-ÿ ]*)$\").astype(str)\n",
        "#below code to simplify redundant labels (i.e. LB CS to LB)\n",
        "#first, make it all uppercase to simplify code\n",
        "DiningDataFull['Unit'] = DiningDataFull['Unit'].str.upper()\n",
        "def unit_rename(unit):\n",
        "    if('LB' in unit) | ('POUND' in unit):\n",
        "        return 'LB'\n",
        "    if('OZ' in unit) | (' Z' in unit):\n",
        "        return 'OZ'\n",
        "    if('GA' in unit) | ('GAL' in unit):\n",
        "        return 'GA'\n",
        "    if('QT' in unit):\n",
        "        return 'QT'\n",
        "    if('PT' in unit) | ('PINT' in unit):\n",
        "        return 'PT'\n",
        "    if('LT' in unit):\n",
        "        return 'LT'\n",
        "    if('BU' in unit) | ('Bushel' in unit): #bushels\n",
        "        return 'BU'\n",
        "    if('KG' in unit):\n",
        "        return 'KG'\n",
        "    if('GR' in unit): #grams\n",
        "        return 'GR'\n",
        "    if('ML' in unit): #milliliters\n",
        "        return 'ML'\n",
        "    if('CN' in unit) | ('Can' in unit):\n",
        "        return 'CN'\n",
        "    if('BOTTLE CASE' in unit):\n",
        "        return 'Bottle Case'\n",
        "    return None\n",
        "#Notes: Bottle Case is 64 oz each, find # of can and translate to oz, anything with EA is not included for now (~9000)\n",
        "DiningDataFull['Unit'] = DiningDataFull.apply(lambda d: unit_rename(d['Unit']), axis = 1)\n",
        "\n",
        "#convert cans to OZ\n",
        "#using estimates for weight of cans through https://food.unl.edu/article/how-interpret-can-size-numbers\n",
        "DiningDataFull = DiningDataFull.replace({'#10 CN' : '110.5 OZ'}, regex = True)\n",
        "DiningDataFull = DiningDataFull.replace({'#10 Can' : '110.5 OZ'}, regex = True)\n",
        "DiningDataFull = DiningDataFull.replace({'#300 CN' : '15 OZ'}, regex = True)\n",
        "DiningDataFull = DiningDataFull.replace({'CN' : 'OZ'})\n",
        "#convert bottle case to OZ\n",
        "DiningDataFull = DiningDataFull.replace({' Bottle Case' : '/64 OZ'}, regex = True)\n",
        "DiningDataFull = DiningDataFull.replace({'BOTTLE CASE' : 'OZ'})\n",
        "\n",
        "#extract clean item names\n",
        "#make everything uppercase and remove zz's in front of some of the item descriptions\n",
        "DiningDataFull['Vendor Item Description'] = DiningDataFull['Vendor Item Description'].str.upper()\n",
        "DiningDataFull['Vendor Item Description'] = DiningDataFull['Vendor Item Description'].apply(lambda x: re.sub(r'^ZZ ', '', x))\n",
        "DiningDataFull['Vendor Item'] = DiningDataFull['Vendor Item Description'].str.extract(r'(.*),')\n",
        "DiningDataFull['Vendor Item'] = DiningDataFull['Vendor Item'].str.upper()\n",
        "print(DiningDataFull.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPuQ7DJMOeH3",
        "outputId": "19254e45-c99d-40c0-8a5e-10b1007bdb9f",
        "cellView": "form"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Unit Name    Vendor Purchase Date Vendor Item ID  \\\n",
            "0  Marketplace  US Foods    2019-07-01        5018999   \n",
            "1  Marketplace  US Foods    2019-07-01        5400692   \n",
            "2  Marketplace  US Foods    2019-07-01        8012643   \n",
            "3  Marketplace  US Foods    2019-07-01         731349   \n",
            "4  Marketplace  US Foods    2019-07-01          68106   \n",
            "\n",
            "                             Vendor Item Description  \\\n",
            "0  POTATO, FRENCH-FRY 3/4 X3/8 STEAK CUT SKIN-ON ...   \n",
            "1  POTATO, FRENCH-FRY SPIRAL COATED SEASONED TFF ...   \n",
            "2  POTATO, FRENCH-FRY 1/2 CRINKLE-CUT TFF EXTRA-L...   \n",
            "3                POTATO, HASH BROWN SHRED COOKED REF   \n",
            "4    POTATO, TATER NUGGET PARFRIED FROZEN HASH BROWN   \n",
            "\n",
            "  Vendor Item Purchase Unit                              Product Group  \\\n",
            "0                    6/5 LB  APPETIZERS, ENTREES, & POTATOES REF & FZN   \n",
            "1                    6/5 LB  APPETIZERS, ENTREES, & POTATOES REF & FZN   \n",
            "2                  6/4.5 LB  APPETIZERS, ENTREES, & POTATOES REF & FZN   \n",
            "3                   2/10 LB  APPETIZERS, ENTREES, & POTATOES REF & FZN   \n",
            "4                    6/5 LB  APPETIZERS, ENTREES, & POTATOES REF & FZN   \n",
            "\n",
            "                Brand  Receive Quantity Priority 1 Priority 2 Priority 3 Unit  \\\n",
            "0  LW PRIVATE RESERVE              44.0        NaN        NaN        NaN   LB   \n",
            "1      LAMBS SEASONED              15.0        NaN        NaN        NaN   LB   \n",
            "2       LAMBS SUPREME              15.0        NaN        NaN        NaN   LB   \n",
            "3  CROSS VALLEY FARMS              20.0        NaN        NaN        NaN   LB   \n",
            "4             MONARCH              10.0        NaN        NaN        NaN   LB   \n",
            "\n",
            "  Vendor Item  \n",
            "0      POTATO  \n",
            "1      POTATO  \n",
            "2      POTATO  \n",
            "3      POTATO  \n",
            "4      POTATO  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Make a new column called `Total Amount` for the total amount of food in the current unit of measurement, before converting to grams. Make a new column called `Total Amount(g)` for converting all units to the equivalent value in grams, then filter out main descriptor word(s) in `Vendor Item Description` into a new column called `Food Name`.\n",
        "\n",
        "---\n",
        "\n",
        "Take the column with units in grams and multiply by the `Receive Quantity` if provided into a new column called `Total Grams`. If there is no value in `Receive Quantity`, then assume it is the value 1.\n",
        "\n",
        "---\n",
        "Note on Conversions: Most of these conversions are estimated to the nearest tenth. **More accurate calculations can be found later**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "PQbuaCZyGnUQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title DDReduced and DDReducedLabeled\n",
        "#make a new dataset for just entries with known units\n",
        "DDReduced = DiningDataFull[DiningDataFull['Unit'].notna()]\n",
        "#print(DDReduced.head())\n",
        "\n",
        "#make csv to manually edit unclean entries\n",
        "#DDReduced.to_csv('DDReduced.csv', encoding = 'utf-8-sig')\n",
        "#files.download('DDReduced.csv')\n",
        "\n",
        "DDReducedLabeled = pd.read_csv('/content/drive/MyDrive/Data+/DDReducedLabeled.csv')\n",
        "\n",
        "DDReducedLabeled['Purchase Date'] = DDReducedLabeled.apply(lambda d: datetime.strptime(d['Purchase Date'], '%m/%d/%Y').date(), axis = 1)"
      ],
      "metadata": {
        "id": "uwPR4JriY-bM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Find total amount of food\n",
        "#find total amount of food in original unit before converting to grams\n",
        "DDReduced = DDReduced.copy()\n",
        "DDReduced['Total Amount'] = DDReduced['Vendor Item Purchase Unit'].str.extract(r'^[a-zA-Z]* ?-?/? ?([0-9]*/?[0-9.]*-?[0-9.]*)')\n",
        "DDReduced['Range'] = DDReduced['Total Amount'].str.extract(r'([0-9.]*-[0-9.]*)')\n",
        "DDReduced['Range'] = DDReduced['Range'].astype(str)\n",
        "DDReduced['Range'] = DDReduced['Range'].replace({'nan' : '0'})\n",
        "DDReduced['Range Average'] = DDReduced['Range'].replace({'-' : '+'}, regex = True)\n",
        "DDReduced['Range Average'] = DDReduced.apply(lambda d: eval(d['Range Average']), axis = 1)\n",
        "DDReduced['Range Average'] /= 2\n",
        "\n",
        "has_slash = ~(DDReduced['Total Amount'].str.contains('/')) & (DDReduced['Total Amount'].str.len() > 0)\n",
        "DDReduced.loc[has_slash, 'Total Amount'] = (\n",
        "    '1/' + DDReduced.loc[has_slash, 'Total Amount']\n",
        ")\n",
        "\n",
        "has_range = DDReduced['Total Amount'].str.contains('-')\n",
        "DDReduced.loc[has_range, 'Total Amount'] = (\n",
        "    DDReduced.loc[has_range, 'Total Amount'].str.split('/').str[0]\n",
        "    + '/'\n",
        "    + DDReduced.loc[has_range, 'Range Average'].astype(str)\n",
        ")\n",
        "\n",
        "just_unit = (DDReduced['Total Amount'] == '') & ~(DDReduced['Vendor Item Purchase Unit'].isna())\n",
        "DDReduced.loc[just_unit, 'Total Amount'] = '1'\n",
        "\n",
        "DDReduced = DDReduced.drop(['Range', 'Range Average'], axis = 1)\n",
        "\n",
        "DDReduced['Total Amount'] = DDReduced['Total Amount'].replace({'' : '0'})\n",
        "DDReduced['Receive Quantity'] = DDReduced['Receive Quantity'].fillna(0)\n",
        "DDReduced = DDReduced[DDReduced['Receive Quantity'] != 0] #get rid of any rows that were not received\n",
        "DDReduced['Total Amount'] = DDReduced['Total Amount'].replace({'/' : '*'}, regex = True)\n",
        "DDReduced['Total Amount'] = DDReduced.apply(lambda d: eval(d['Total Amount']), axis = 1)\n",
        "DDReduced['Total Amount'] = DDReduced['Total Amount'].astype(float) * DDReduced['Receive Quantity'].astype(float)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "sbvWefOrZl4A"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Convert all units to grams\n",
        "def convert_units(row):\n",
        "    if row['Unit'] == 'LB':\n",
        "        return row['Total Amount'] * 453.6\n",
        "    if row['Unit'] == 'OZ':\n",
        "        return row['Total Amount'] * 28.35\n",
        "    if row['Unit'] == 'GA':\n",
        "        return row['Total Amount'] * 3785.4 #assuming density of water, most drinks are MORE dense so number is underestimate\n",
        "    if row['Unit'] == 'QT':\n",
        "        return row['Total Amount'] * 3785.4 / 4\n",
        "    if row['Unit'] == 'PT':\n",
        "        return row['Total Amount'] * 3785.4 / 8\n",
        "    if (row['Unit'] == 'LT') | (row['Unit'] == 'KG'):\n",
        "        return row['Total Amount'] * 1000 #also assuming density of water, most drinks MORE dense\n",
        "    if (row['Unit'] == 'ML') | (row['Unit'] == 'G'):\n",
        "        return row['Total Amount'] * 453.6\n",
        "    return 0\n",
        "DDReduced['Total Amount(kg)'] = DDReduced.apply(convert_units, axis = 1) / 1000\n",
        "\n",
        "#modify `Product Group` column\n",
        "DDReduced = DDReduced[DDReduced['Product Group'].notna()]\n",
        "DDReduced['Product Group'] = DDReduced['Product Group'].str.upper() #make uppercase to simplify code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnLSVqA0I4K4",
        "outputId": "4d307695-9a7e-4ef6-9437-62e34ed0d9cd",
        "cellView": "form"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-a9685a9ad7cb>:22: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  DDReduced['Product Group'] = DDReduced['Product Group'].str.upper() #make uppercase to simplify code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Excluded rows\n",
        "print(\"Excluded rows: \", DiningDataFull.shape[0] - DDReduced.shape[0])\n",
        "#print(DDReduced.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "dnbKU7U_bOZU",
        "outputId": "23d78502-e6e5-43c1-e005-3038c28fb168"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excluded rows:  17161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "#NLP\n",
        "\n",
        "Come back later and try this, too difficult for now\n",
        "---"
      ],
      "metadata": {
        "id": "Bzh6JeBvnyts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NLP packages\n",
        "# from google.colab import files\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import CountVectorizer\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "YbF2KcFuoBlJ",
        "cellView": "form"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NLP labeled data\n",
        "#Create training set with ~10000 random entries\n",
        "#DDtest = DDReduced.sample(10000)\n",
        "#DDtest.to_csv('DDtest.csv', encoding = 'utf-8-sig')\n",
        "#files.download('DDtest.csv')\n",
        "\n",
        "# DDLabeled = pd.read_csv('DDLabeled.csv')\n",
        "\n",
        "# print(DDLabeled.head())\n",
        "\n",
        "#Notes on labels:\n",
        "#syrup is 2/3 sugar 1/3 water for emissions\n",
        "#many vegetables are labeled \"Leafy greens\" for now\n",
        "#smoothies are labeled smoothie for now, can find fruits in each or average smoothie emissions later\n",
        "#mushrooms need emissions numbers\n",
        "#fruit is used to label misc less-common fruits\n",
        "#avocados need emission numbers\n",
        "#dressings need emission numbers\n",
        "#squashes need emission numbers"
      ],
      "metadata": {
        "id": "iQTPLgACnybR",
        "cellView": "form"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NLP model\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Preprocess the data\n",
        "# text_data = DDLabeled['Vendor Item Description']\n",
        "# labels = DDLabeled['Product Group']\n",
        "\n",
        "# # Label encode the target variable\n",
        "# label_encoder = LabelEncoder()\n",
        "# labels = label_encoder.fit_transform(labels)\n",
        "\n",
        "# # Tokenize the text data\n",
        "# tokenizer = Tokenizer()\n",
        "# tokenizer.fit_on_texts(text_data)\n",
        "# vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "# # Convert text to sequences\n",
        "# sequences = tokenizer.texts_to_sequences(text_data)\n",
        "\n",
        "# # Pad sequences to have equal length\n",
        "# max_sequence_length = max(len(seq) for seq in sequences)\n",
        "# padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# train_size = int(0.8 * len(padded_sequences))\n",
        "# train_text = padded_sequences[:train_size]\n",
        "# train_labels = labels[:train_size]\n",
        "# test_text = padded_sequences[train_size:]\n",
        "# test_labels = labels[train_size:]\n",
        "\n",
        "# # Define the neural network architecture\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(vocab_size, 100, input_length=max_sequence_length),\n",
        "#     tf.keras.layers.LSTM(64),\n",
        "#     tf.keras.layers.Dense(64, activation='relu'),\n",
        "#     tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(train_text, train_labels, epochs=20, batch_size=32, validation_data=(test_text, test_labels))"
      ],
      "metadata": {
        "id": "9Wyc352gcUYL",
        "cellView": "form"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title NLP testing\n",
        "# # Evaluate the model\n",
        "# loss, accuracy = model.evaluate(test_text, test_labels)\n",
        "# print('Test Loss:', loss)\n",
        "# print('Test Accuracy:', accuracy)\n",
        "\n",
        "# # Make predictions on new data\n",
        "# new_text = ['BEET, WHOLE PEELED COOKED 17.6 OZ VACUUM-PACK REF', 'BEIGELS CHALLAH']\n",
        "# new_sequences = tokenizer.texts_to_sequences(new_text)\n",
        "# new_padded_sequences = pad_sequences(new_sequences, maxlen=max_sequence_length)\n",
        "# predictions = model.predict(new_padded_sequences)\n",
        "# predicted_labels = label_encoder.inverse_transform(tf.argmax(predictions, axis=1))\n",
        "# print('Predicted Labels:', predicted_labels)"
      ],
      "metadata": {
        "id": "7rij9QdMz9am",
        "cellView": "form"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Copy manually labeled data\n",
        "#last time manually labeled was 6/21/23\n",
        "DDReduced = DDReducedLabeled"
      ],
      "metadata": {
        "id": "5Fd0Apt5cnWe",
        "cellView": "form"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Explore labeled data\n",
        "print(DDReduced['Vendor Item'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vn_NbAfJ60cf",
        "outputId": "93e5a5fa-3ce2-480a-dc81-709629906ef6",
        "cellView": "form"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHEESE          3250\n",
            "BREAD           2912\n",
            "POTATO          2732\n",
            "CHICKEN         2507\n",
            "TOMATO          2131\n",
            "                ... \n",
            "CORN SOUP          1\n",
            "CHICKEN SOUP       1\n",
            "SEAWEED            1\n",
            "ENDIVE             1\n",
            "PAPAYA             1\n",
            "Name: Vendor Item, Length: 320, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Item label cleaning\n",
        "#label others meats that are not already labeled\n",
        "meat_not_labeled = (DDReduced['Product Group'].str.contains('MEAT', regex = True) | \\\n",
        "                    DDReduced['Product Group'].str.contains('MEATS', regex = True)) & \\\n",
        "                    ~(DDReduced['Product Group'].str.contains('SUBSTITUTE', regex = True))\n",
        "                    #mask meats not labeled, but not substitutes\n",
        "vendor_item_na = (DDReduced['Vendor Item'].isna())\n",
        "\n",
        "#if meat not labeled, but `Vendor Item` is NaN, read first word of `Vendor Item Description`\n",
        "DDReduced.loc[meat_not_labeled & vendor_item_na, 'Vendor Item'] = \\\n",
        "    (DDReduced.loc[meat_not_labeled & vendor_item_na, 'Vendor Item Description'].str.split(' ').str[0])\n",
        "\n",
        "#meat substitute labeling part 1\n",
        "is_meat_sub = (DDReduced['Vendor Item'].str.contains('SUB')) | \\\n",
        "              (DDReduced['Vendor Item'] == 'BEAN')\n",
        "DDReduced.loc[is_meat_sub & meat_not_labeled, 'Product Group'] = 'MEAT SUBSTITUTE'\n",
        "\n",
        "#dictionary of known meats, if not in dictionary, read next word\n",
        "meat_dict = ['SUB', 'BEAN', 'SAUSAGE', 'PEPPERONI', 'HOT DOG', 'CORN DOG', \\\n",
        "             'DOG', 'SALAMI', 'MEATBALL', 'CHICKEN', 'TURKEY', 'DUCK', \\\n",
        "             'CORNISH HEN', 'BEEF', 'CORNED BEEF', 'ROAST', 'PASTRAMI', \\\n",
        "             'GYRO MEAT', 'LAMB', 'PORK', 'HAM', 'BACON', 'CRAB CAKE', \\\n",
        "             'CRABMEAT', 'COD', 'SALMON', 'MAHI MAHI', 'SHRIMP', 'TUNA', \\\n",
        "             'CATFISH', 'MUSSEL', 'FLOUNDER', 'FISH', 'SURIMI', 'POLLOCK', \\\n",
        "             'SCALLOP', 'LOBSTER', 'GROUPER', 'CRAWFISH', 'ALL-BEEF', 'CHUCK']\n",
        "meat_in_dict = ~DDReduced['Vendor Item'].isin(meat_dict)\n",
        "\n",
        "#iterate through words until meat is found\n",
        "def extract_vendor_item(description):\n",
        "    words = description.split()\n",
        "    for word in words:\n",
        "        if word in meat_dict:\n",
        "            return word\n",
        "    return\n",
        "DDReduced.loc[meat_in_dict & meat_not_labeled, 'Vendor Item'] = \\\n",
        "        DDReduced.loc[meat_in_dict & meat_not_labeled, 'Vendor Item Description'].apply(lambda x: extract_vendor_item(x))\n",
        "\n",
        "#label meat sub again if missed in first run\n",
        "is_meat_sub = (DDReduced['Vendor Item'].str.contains('SUB')) | \\\n",
        "              (DDReduced['Vendor Item'] == 'BEAN')\n",
        "DDReduced.loc[is_meat_sub & meat_not_labeled, 'Product Group'] = 'MEAT SUBSTITUTE'\n",
        "\n",
        "#label sausage and sausage-related foods\n",
        "sausage_like = (DDReduced['Vendor Item'].str.contains('SAUSAGE')) | \\\n",
        "               (DDReduced['Vendor Item'] == 'PEPPERONI') | \\\n",
        "               (DDReduced['Vendor Item'].str.contains('DOG')) | \\\n",
        "               (DDReduced['Vendor Item'] == 'SALAMI')\n",
        "DDReduced.loc[sausage_like, 'Product Group'] = 'SAUSAGE'\n",
        "\n",
        "#label meatballs (half pork, half beef)\n",
        "is_meatball = (DDReduced['Vendor Item'] == 'MEATBALL')\n",
        "DDReduced.loc[is_meatball, 'Product Group'] = 'MEATBALL'\n",
        "\n",
        "#label poultry\n",
        "is_poultry = (DDReduced['Vendor Item'] == 'CHICKEN') | \\\n",
        "             (DDReduced['Vendor Item'] == 'TURKEY') | \\\n",
        "             (DDReduced['Vendor Item'] == 'DUCK')\n",
        "DDReduced.loc[is_poultry & meat_not_labeled, 'Product Group'] = 'POULTRY'\n",
        "\n",
        "#label beef\n",
        "is_beef = (DDReduced['Vendor Item'].str.contains('BEEF')) | \\\n",
        "          (DDReduced['Vendor Item'].str.contains('ROAST')) | \\\n",
        "          (DDReduced['Vendor Item'] == 'PASTRAMI') | \\\n",
        "          (DDReduced['Vendor Item'] == 'CHUCK')\n",
        "DDReduced.loc[is_beef & meat_not_labeled, 'Product Group'] = 'BEEF'\n",
        "\n",
        "#label gyro meat\n",
        "is_gyro_meat = (DDReduced['Vendor Item'].str.contains('GYRO MEAT')) | \\\n",
        "               (DDReduced['Vendor Item'] == 'LAMB')\n",
        "DDReduced.loc[is_gyro_meat & meat_not_labeled, 'Product Group'] = 'LAMB'\n",
        "#most common ingredient in gyro meat, technically has beef but the numbers are very similar\n",
        "\n",
        "#label pork\n",
        "is_pork = (DDReduced['Vendor Item'] == 'PORK') | \\\n",
        "          (DDReduced['Vendor Item'] == 'HAM') | \\\n",
        "          (DDReduced['Vendor Item'] == 'BACON')\n",
        "DDReduced.loc[is_pork & meat_not_labeled, 'Product Group'] = 'PORK'\n",
        "\n",
        "#label seafood\n",
        "is_seafood = (DDReduced['Vendor Item'].str.contains('CRAB')) | \\\n",
        "          (DDReduced['Vendor Item'] == 'COD') | \\\n",
        "          (DDReduced['Vendor Item'] == 'SALMON') | \\\n",
        "          (DDReduced['Vendor Item'] == 'MAHI MAHI') | \\\n",
        "          (DDReduced['Vendor Item'] == 'SHRIMP') | \\\n",
        "          (DDReduced['Vendor Item'] == 'TUNA') | \\\n",
        "          (DDReduced['Vendor Item'] == 'CATFISH') | \\\n",
        "          (DDReduced['Vendor Item'] == 'MUSSEL') | \\\n",
        "          (DDReduced['Vendor Item'] == 'FLOUNDER') | \\\n",
        "          (DDReduced['Vendor Item'] == 'FISH') | \\\n",
        "          (DDReduced['Vendor Item'] == 'SURIMI') | \\\n",
        "          (DDReduced['Vendor Item'] == 'POLLOCK') | \\\n",
        "          (DDReduced['Vendor Item'] == 'SCALLOP') | \\\n",
        "          (DDReduced['Vendor Item'] == 'LOBSTER') | \\\n",
        "          (DDReduced['Vendor Item'] == 'GROUPER') | \\\n",
        "          (DDReduced['Vendor Item'] == 'CRAWFISH')\n",
        "#Surimi is made of fish\n",
        "DDReduced.loc[is_seafood & meat_not_labeled, 'Product Group'] = 'SEAFOOD'\n",
        "\n",
        "#label sodas\n",
        "is_soda = DDReduced['Brand'] == 'Durham Coca Cola'\n",
        "DDReduced.loc[is_soda, 'Product Group'] = 'SODA'"
      ],
      "metadata": {
        "id": "QCCi_esIeP8z",
        "cellView": "form"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load emissions csv and create emission ratio variables\n",
        "#read csv here when done\n",
        "#_______________________\n",
        "\n",
        "#CURRENT VALUES: from CO2 spreadsheet above (Poore and Nemecek 2018) (6/5/23)\n",
        "#beef_emission_ratio = 21.3 #US for retail beef, 65% of CW, https://www.sciencedirect.com/science/article/pii/S0308521X18305675?via%3Dihub#s0085\n",
        "beef_emission_ratio = 40 #UK beef\n",
        "pork_emission_ratio = 10.7 #Ham (CO2)\n",
        "poultry_emission_ratio = 4.9 #chicken for North America (PN18)\n",
        "lamb_emission_ratio = 40.0 #using global avg, lower than europe avg.\n",
        "seafood_emission_ratio = 13.6 #average of three common fish\n",
        "eggs_emission_ratio = 3.7 #avg for US (CO2)(PN18)\n",
        "meatsub_emission_ratio = 2.19 #(https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9936781/ , Mejia et al., 2020)\n",
        "meatball_emission_ratio = .5 * beef_emission_ratio + .5 * pork_emission_ratio\n",
        "sausage_emission_ratio = 8.85 #Sausage (CO2)\n",
        "#add more values here as the data gets more clean\n",
        "#later, replace with newer spreadsheet\n",
        "\n",
        "print(\"beef: \", beef_emission_ratio, 'kg CO2e/kg')\n",
        "print(\"pork: \", pork_emission_ratio, 'kg CO2e/kg')\n",
        "print(\"poultry: \", poultry_emission_ratio, 'kg CO2e/kg')\n",
        "print(\"lamb: \", lamb_emission_ratio, 'kg CO2e/kg')\n",
        "print(\"seafood: \", seafood_emission_ratio, 'kg CO2e/kg')\n",
        "print(\"eggs: \", eggs_emission_ratio, 'kg CO2e/kg')\n",
        "print(\"meatsub: \", meatsub_emission_ratio, 'kg CO2e/kg')\n",
        "print(\"meatball: \", meatball_emission_ratio, 'kg CO2e/kg')\n",
        "print(\"sausage: \", sausage_emission_ratio, 'kg CO2e/kg')\n",
        "\n",
        "#print(CO2.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRVwXabqo36T",
        "outputId": "fb862039-eb75-4440-fb96-a656048ab361"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beef:  40 kg CO2e/kg\n",
            "pork:  10.7 kg CO2e/kg\n",
            "poultry:  4.9 kg CO2e/kg\n",
            "lamb:  40.0 kg CO2e/kg\n",
            "seafood:  13.6 kg CO2e/kg\n",
            "eggs:  3.7 kg CO2e/kg\n",
            "meatsub:  2.19 kg CO2e/kg\n",
            "meatball:  25.35 kg CO2e/kg\n",
            "sausage:  8.85 kg CO2e/kg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Calculate Carbon Emissions\n",
        "#only meats, meat alternatives, and eggs done so far\n",
        "#print(DDReduced['Product Group'].value_counts())\n",
        "\n",
        "def calc_emissions(row):\n",
        "    if row['Product Group'] == 'BEEF':\n",
        "        return row['Total Amount(kg)'] * beef_emission_ratio\n",
        "    if row['Product Group'] == 'PORK':\n",
        "        return row['Total Amount(kg)'] * pork_emission_ratio\n",
        "    if row['Product Group'] == 'SEAFOOD':\n",
        "        return row['Total Amount(kg)'] * seafood_emission_ratio\n",
        "    if row['Product Group'] == 'MEAT SUBSTITUTE':\n",
        "        return row['Total Amount(kg)'] * meatsub_emission_ratio\n",
        "    if row['Product Group'] == 'LAMB':\n",
        "        return row['Total Amount(kg)'] * lamb_emission_ratio\n",
        "    if (row['Product Group'] == 'CHICKEN') | (row['Product Group'] == 'POULTRY') | \\\n",
        "       (row['Product Group'] == 'TURKEY') | (row['Product Group'] == 'DUCK'):\n",
        "        return row['Total Amount(kg)'] * beef_emission_ratio\n",
        "    if row['Product Group'] == 'EGGS':\n",
        "        return row['Total Amount(kg)'] * eggs_emission_ratio\n",
        "    if row['Product Group'] == 'MEATBALL':\n",
        "        return row['Total Amount(kg)'] * meatball_emission_ratio\n",
        "    if row['Product Group'] == 'SAUSAGE':\n",
        "        return row['Total Amount(kg)'] * sausage_emission_ratio\n",
        "    return 0\n",
        "\n",
        "DDReduced['CO2e(kg)'] = DDReduced.apply(calc_emissions, axis = 1)\n",
        "\n",
        "total_food_amount_kg = DDReduced['Total Amount(kg)'].sum()\n",
        "total_food_amount_calced_kg = DDReduced[DDReduced['CO2e(kg)'] != 0]['Total Amount(kg)'].sum()\n",
        "percent_food_calced = total_food_amount_calced_kg / total_food_amount_kg * 100\n",
        "\n",
        "print('The percentage of food (by weight) with calculated carbon emissions so far is: ', percent_food_calced, \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beM1jtkMe44Q",
        "outputId": "8053b242-7311-404c-b70f-f94d8e3166c4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of food (by weight) with calculated carbon emissions so far is:  63.201983204801756 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create separated dataframes\n",
        "location_col = DDReduced['Unit Name']\n",
        "DDMarketplace = DDReduced[location_col == \"Marketplace\"]\n",
        "DDDuML = DDReduced[location_col == \"DuML\"]\n",
        "DDTrinity = DDReduced[location_col == \"Trinity\"]\n",
        "DDFreeman = DDReduced[location_col == \"Freeman\"]\n",
        "\n",
        "date_col = DDReduced['Purchase Date']\n",
        "DDFY20 = DDReduced[(date_col >= pd.Timestamp(2019, 7, 1).date()) & (date_col < pd.Timestamp(2020, 6, 30).date())]\n",
        "DDFY21 = DDReduced[(date_col >= pd.Timestamp(2020, 7, 1).date()) & (date_col < pd.Timestamp(2021, 6, 30).date())]\n",
        "DDFY22 = DDReduced[(date_col >= pd.Timestamp(2021, 7, 1).date()) & (date_col < pd.Timestamp(2022, 6, 30).date())]\n",
        "DDFY23 = DDReduced[(date_col >= pd.Timestamp(2022, 7, 1).date()) & (date_col < pd.Timestamp(2023, 6, 30).date())]"
      ],
      "metadata": {
        "id": "mJYaZdBsykLC"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Analysis\n",
        "#later, download a csv from previous code and move this to a new notebook\n",
        "total_food_emissions_2022 = DDFY22['CO2e(kg)'].sum()\n",
        "total_duke_emissions_2022 = 194346000 #in kg, from 2022 GHG emissions\n",
        "\n",
        "total_food_amount_kg_2022 = DDFY22['Total Amount(kg)'].sum()\n",
        "total_food_amount_calced_kg_2022 = DDFY22[DDFY22['CO2e(kg)'] != 0]['Total Amount(kg)'].sum()\n",
        "percent_food_calced_2022 = total_food_amount_calced_kg_2022 / total_food_amount_kg_2022 * 100\n",
        "\n",
        "print('The percentage of food (by weight) with calculated carbon emissions so far in 2022 is: ', percent_food_calced_2022, \"%\")\n",
        "print('')\n",
        "print(\"Of what has been calculated, food is \", total_food_emissions_2022 / total_duke_emissions_2022 * 100, \"% of Duke's total GHG emissions in 2022\")\n",
        "print(\"The value in Metric Tons is: \", total_food_emissions_2022 / 1000)\n",
        "print(\"If food is not included in Duke's calculations, then the reported amount is: \", total_duke_emissions_2022 / (total_duke_emissions_2022 + total_food_emissions_2022) * 100, \"% of the real total emissions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5s8NMgNxExG",
        "outputId": "75125e83-00c1-42b7-eac9-45d648c8d957"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of food (by weight) with calculated carbon emissions so far in 2022 is:  62.54326134096214 %\n",
            "\n",
            "Of what has been calculated, food is  28.9413445855332 % of Duke's total GHG emissions in 2022\n",
            "The value in Metric Tons is:  56246.34554820036\n",
            "If food is not included in Duke's calculations, then the reported amount is:  77.55464340893779 % of the real total emissions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualize\n",
        "data = [22.378, 77.622]\n",
        "explode = [0.1, 0]\n",
        "keys = ['Food Emissions\\n(58472 Megatons CO2e)', \\\n",
        "        'All Other Emissions\\n(194346 Megatons CO2e)']\n",
        "\n",
        "colors = ['#5da45a', '#7c5aa4']\n",
        "\n",
        "plt.pie(data, labels=keys, colors=colors, autopct='%.3f%%', \\\n",
        "        explode = explode)\n",
        "plt.suptitle('Percent of Duke\\'s Fiscal Year 2022 Carbon Emissions from Food', fontsize = 15)\n",
        "plt.title('(Only meat products have been calculated so far)', fontsize = 10)\n",
        "\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "7bP6p08XWMwN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DD22.to_csv('DD22.csv', encoding = 'utf-8-sig')\n",
        "#files.download('DD22.csv')"
      ],
      "metadata": {
        "id": "Z9RuX09thkeN"
      },
      "execution_count": 61,
      "outputs": []
    }
  ]
}